{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8WotcdCk/umXC18/zGgGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daithi333/colab-notebooks/blob/main/query_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "x1Zcr2vE79_P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0LLxe4hojp9"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install bitsandbytes accelerate xformers einops\n",
        "!pip -q install datasets loralib sentencepiece\n",
        "!pip -q install pypdf\n",
        "!pip -q install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install chromadb"
      ],
      "metadata": {
        "id": "xQfxxTFmpmRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai\n",
        "!pip -q install tiktoken"
      ],
      "metadata": {
        "id": "nC66kyGKqw22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from langchain.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from huggingface_hub import notebook_login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "L6mtjDlTq3ne"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Documents and extract text"
      ],
      "metadata": {
        "id": "BTJvaZXDumNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir docs"
      ],
      "metadata": {
        "id": "4naFlpcHtrEH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = []\n",
        "\n",
        "for file in os.listdir(\"docs\"):\n",
        "  path = f\"./docs/{file}\"\n",
        "  if file.endswith(\".pdf\"):\n",
        "    loader = PyPDFLoader(path)\n",
        "  elif file.endswith(\".docx\") or file.endswith(\".doc\"):\n",
        "    loader = Docx2txtLoader(path)\n",
        "  elif file.endswith(\".docx\") or file.endswith(\".doc\"):\n",
        "    loader = TextLoader(path)\n",
        "  else:\n",
        "    raise ValueError(f\"Unrecognised extension on {file}\")\n",
        "\n",
        "  document.extend(loader.load())"
      ],
      "metadata": {
        "id": "s7S5nOUXvEfC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document"
      ],
      "metadata": {
        "id": "sESZ4ViAxfZ3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(document)"
      ],
      "metadata": {
        "id": "pl_goJZux7o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Document into chunks"
      ],
      "metadata": {
        "id": "MD2qnh9cyq40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "document_chunks = document_splitter.split_documents(document)\n",
        "len(document_chunks)"
      ],
      "metadata": {
        "id": "SwkGgF0ByCjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks[0]"
      ],
      "metadata": {
        "id": "-PLafvnbyZdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Embeddings"
      ],
      "metadata": {
        "id": "p59H9sutyicC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cost associated with using OpenAI\n",
        "openai_api_key = input(f\"Enter OpenAI key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "rNHodKvIzT7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "o4hAsljEycqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "id": "SfKrfRrmzF-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Chroma Vector Db"
      ],
      "metadata": {
        "id": "KjgWiCgqzyrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(document_chunks, embedding=embeddings, persist_directory=\"./data\")"
      ],
      "metadata": {
        "id": "PVmTZJEizniR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "b2vF41e_0TRl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using HuggingFace"
      ],
      "metadata": {
        "id": "kX_z5qvu6wcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Login to HuggingFace Hub to download model"
      ],
      "metadata": {
        "id": "vwhTUvED7Dgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "cYEJlhJK0WmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Llama 2 7B LLM"
      ],
      "metadata": {
        "id": "iiXQIgLD2gIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    use_auth_token=True,\n",
        "    )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    use_auth_token=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    # load_in_8bit=True,\n",
        "    load_in_4bit=True,\n",
        ")"
      ],
      "metadata": {
        "id": "w1nsw0ec2FPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create HuggingFace Pipeline"
      ],
      "metadata": {
        "id": "Y5_lqbIWl0Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map='auto',\n",
        "    max_new_tokens=512,\n",
        "    min_new_tokens=1,\n",
        "    top_k=30\n",
        ")"
      ],
      "metadata": {
        "id": "UcPR_xBBlmwa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature': 0})"
      ],
      "metadata": {
        "id": "2HarqjxXmRA5"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using OpenAI"
      ],
      "metadata": {
        "id": "Ef4iVGYp59fL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "QGNxFwtOmuk8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "id": "33DfAbFQm7PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create memory object to store conversation history"
      ],
      "metadata": {
        "id": "U9XtEWfhnROq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "cXlbCnHznMUb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Conversation retrieval QA chain"
      ],
      "metadata": {
        "id": "F8LLcWrMn4jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ConversationalRetrievalQA chain builds on RetrievalQAChain to provide a chat history component."
      ],
      "metadata": {
        "id": "G93UULqtoJYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 6}),\n",
        "    verbose=False,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "ERdMc8ifntnU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = docs_qa({\"question\": \"Summarise briefly the process for taking an AWS Associate exam\"})"
      ],
      "metadata": {
        "id": "1qL1Iamzo24x"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Wffz1H37pcBp",
        "outputId": "da1a77bd-f04a-4375-91a0-fcf2c1aac808"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The provided context does not mention any specific pre-requisites for taking the AWS Certified Solutions Architect - Associate (SAA-C03) exam. However, it is mentioned that the target candidate should have at least 1 year of hands-on experience designing cloud solutions that use AWS services. It is always recommended to review the official AWS certification website for the most up-to-date information on any pre-requisites or requirements for the exam.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---------------------------------\")\n",
        "print(\"Welcome to the Document Query bot\")\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "while True:\n",
        "  query = input(f\"Prompt:\")\n",
        "  if query in [\"exit\", \"quit\" \"q\", \"f\"]:\n",
        "    print(\"Exiting\")\n",
        "    sys.exit()\n",
        "  if query == \"\":\n",
        "    continue\n",
        "  result = docs_qa({\"question\": query})\n",
        "  print(f\"Answer: {result['answer']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0XVXGeMHp-8k",
        "outputId": "93d27edd-cd98-4847-a621-1f00d2c4f559"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Welcome to the Document Query bot\n",
            "---------------------------------\n",
            "Prompt:How much experience is required to take the AWS Solutions Architect exam?\n",
            "Answer: The required level of experience to take the AWS Solutions Architect - Associate (SAA-C03) exam is at least 1 year of hands-on experience designing cloud solutions that use AWS services.\n",
            "Prompt:What other pre-requisites are there?\n",
            "Answer: The provided context does not mention any specific pre-requisites for taking the AWS Certified Solutions Architect - Associate (SAA-C03) exam. However, it is mentioned that the target candidate should have at least 1 year of hands-on experience designing cloud solutions that use AWS services. It is always recommended to review the official AWS certification website for the most up-to-date information on any pre-requisites or requirements for the exam.\n",
            "Prompt:exit\n",
            "Exiting\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}